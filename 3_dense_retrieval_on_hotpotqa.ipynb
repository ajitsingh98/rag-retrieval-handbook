{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dense Retrieval on HotpotQA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /Users/ajitkumarsingh/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages (3.4.1)\n",
      "Requirement already satisfied: faiss-cpu in /Users/ajitkumarsingh/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages (1.10.0)\n",
      "Requirement already satisfied: accelerate in /Users/ajitkumarsingh/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages (1.6.0)\n",
      "Requirement already satisfied: datasets in /Users/ajitkumarsingh/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages (3.5.1)\n",
      "Requirement already satisfied: tqdm in /Users/ajitkumarsingh/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages (4.67.1)\n",
      "Requirement already satisfied: evaluate in /Users/ajitkumarsingh/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages (0.4.3)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /Users/ajitkumarsingh/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages (from sentence-transformers) (4.49.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/ajitkumarsingh/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages (from sentence-transformers) (2.0.1)\n",
      "Requirement already satisfied: scikit-learn in /Users/ajitkumarsingh/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages (from sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: scipy in /Users/ajitkumarsingh/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages (from sentence-transformers) (1.15.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /Users/ajitkumarsingh/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages (from sentence-transformers) (0.29.2)\n",
      "Requirement already satisfied: Pillow in /Users/ajitkumarsingh/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages (from sentence-transformers) (11.1.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in /Users/ajitkumarsingh/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in /Users/ajitkumarsingh/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages (from faiss-cpu) (24.2)\n",
      "Requirement already satisfied: psutil in /Users/ajitkumarsingh/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /Users/ajitkumarsingh/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/ajitkumarsingh/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages (from accelerate) (0.5.3)\n",
      "Requirement already satisfied: filelock in /Users/ajitkumarsingh/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages (from datasets) (3.12.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Users/ajitkumarsingh/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages (from datasets) (15.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/ajitkumarsingh/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /Users/ajitkumarsingh/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages (from datasets) (2.2.0)\n",
      "Requirement already satisfied: requests>=2.32.2 in /Users/ajitkumarsingh/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: xxhash in /Users/ajitkumarsingh/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /Users/ajitkumarsingh/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec[http]<=2025.3.0,>=2023.1.0 in /Users/ajitkumarsingh/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages (from datasets) (2025.3.0)\n",
      "Requirement already satisfied: aiohttp in /Users/ajitkumarsingh/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages (from datasets) (3.11.13)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/ajitkumarsingh/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/ajitkumarsingh/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/ajitkumarsingh/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages (from aiohttp->datasets) (25.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/ajitkumarsingh/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/ajitkumarsingh/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/ajitkumarsingh/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages (from aiohttp->datasets) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/ajitkumarsingh/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/ajitkumarsingh/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ajitkumarsingh/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ajitkumarsingh/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ajitkumarsingh/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ajitkumarsingh/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
      "Requirement already satisfied: sympy in /Users/ajitkumarsingh/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/ajitkumarsingh/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/ajitkumarsingh/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/ajitkumarsingh/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/ajitkumarsingh/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/ajitkumarsingh/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/ajitkumarsingh/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages (from pandas->datasets) (2022.7)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/ajitkumarsingh/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/ajitkumarsingh/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/ajitkumarsingh/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (3.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/ajitkumarsingh/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/ajitkumarsingh/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/ajitkumarsingh/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers faiss-cpu accelerate datasets tqdm evaluate "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/ajitkumarsingh/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/ajitkumarsingh/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer \n",
    "from datasets import load_dataset\n",
    "import faiss \n",
    "import tqdm \n",
    "import torch \n",
    "import pickle \n",
    "import os \n",
    "import numpy as np\n",
    "import json\n",
    "from itertools import chain\n",
    "import re, nltk, evaluate \n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"punkt_tab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = load_dataset(\"hotpot_qa\", \"distractor\", split=\"train[:10000]\")\n",
    "\n",
    "question = hp[\"question\"][:100]\n",
    "gold = hp[\"answer\"][:100]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"BAAI/bge-base-en-v1.5\"\n",
    "encoder  = SentenceTransformer(model_id, device='cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_raw = hp[\"context\"]\n",
    "\n",
    "corpus = []\n",
    "for context in corpus_raw:\n",
    "    corpus.extend(list(chain.from_iterable(context['sentences'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1595 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39697bb626a1411b8ceb50e1f159d9a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1595 [02:27<65:22:00, 147.63s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dbcce18be2d461ab8870f41be33a1b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/1595 [05:32<75:04:23, 169.66s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aa7901798574d468a05524eb237dc71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/1595 [07:37<65:58:40, 149.20s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "070ef371de08415dac32e79f7d5dbd26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/1595 [09:26<58:49:59, 133.12s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ead71b0de0f5425c8b2acbefcf7d72eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/1595 [11:52<60:52:34, 137.83s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa45171b9b6946f48dc712b73b87ed97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/1595 [13:38<56:05:39, 127.09s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1aa8b591a734facb3dba45e73666a69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/1595 [15:23<52:52:41, 119.88s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e614e81347824b0daa9c8dc354adb9cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8/1595 [17:43<55:44:26, 126.44s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb905ce2e22748eda30d13a43871fd09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 9/1595 [20:04<57:42:03, 130.97s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0420eb40c60042f5afa80f22309ebab8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1595 [22:17<57:52:27, 131.45s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3f941c692a443318fa54945b7014a67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 11/1595 [23:50<52:43:32, 119.83s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17fe74b6391e49239538bd480c361899",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 12/1595 [25:32<50:17:07, 114.36s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bba2c5affe884ab398cb44086aa067b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 13/1595 [27:46<52:51:30, 120.28s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31dbd62ec68048abb2439df6567d151a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 14/1595 [29:21<49:29:39, 112.70s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cf7fac03e284e1890e06c1eb7d72daf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 15/1595 [31:36<52:18:30, 119.18s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a474d270a35347e1b750cbd006099267",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 16/1595 [33:34<52:07:09, 118.83s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a310c420592d4a339ab85cc6bc05e087",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 17/1595 [52:09<183:25:44, 418.47s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18d01c9250c649c48ee2c564696f711c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 18/1595 [55:43<156:22:04, 356.96s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6f3089b1d5d4960960eb68ca4342b8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 19/1595 [58:24<130:32:41, 298.20s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba0f58a353124bfa9fcf13b75226d3aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 20/1595 [1:00:44<109:41:09, 250.71s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1420f9d97594116bd3ce7bc7545702e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 21/1595 [1:06:02<118:30:00, 271.03s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04240324d1bb41be8d068e5b865c88c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 22/1595 [1:07:30<94:25:58, 216.12s/it] "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa0f8dae0242464d80ca4072c8b932f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 23/1595 [1:09:05<78:25:42, 179.61s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "776a41c5d6b9446a8884fa8cdbf4a596",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 24/1595 [1:10:40<67:14:57, 154.10s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0756161df93844cb910eac102e0d8769",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 25/1595 [1:14:26<76:40:05, 175.80s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23af8854748b410aa444520e096f4adb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 26/1595 [1:16:33<70:17:13, 161.27s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b278eb5b09c46c3bff3fecd5fd0e526",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch = 256 \n",
    "\n",
    "embeddings = []\n",
    "count = 0\n",
    "for i in tqdm.trange(0, len(corpus), batch):\n",
    "\n",
    "    chunk = encoder.encode(\n",
    "        corpus[i:i+batch], \n",
    "        normalize_embeddings=True,\n",
    "        batch_size = batch,\n",
    "        show_progress_bar=True\n",
    "    )\n",
    "    embeddings.append(chunk.astype(\"float32\"))\n",
    "    if count >=15:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6912, 768)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_embeddings = np.vstack(embeddings)\n",
    "doc_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building FAISS Index\n",
    "\n",
    "**Trial:**\n",
    "- `Exact`\n",
    "- `HNSW`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = doc_embeddings.shape[1]\n",
    "\n",
    "#normalize embeddings\n",
    "faiss.normalize_L2(doc_embeddings)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_flat = faiss.IndexFlatIP(embedding_dim)\n",
    "index_flat.add(doc_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approximately HNSW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "index_hnsw = faiss.IndexHNSWFlat(embedding_dim, 32)\n",
    "index_hnsw.hnsw.efConstruction = 200\n",
    "index_hnsw.add(doc_embeddings)\n",
    "index_hnsw.hnsw.efSearch= 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_q(xs):\n",
    "\n",
    "    return encoder.encode(xs, normalize_embeddings=True, \n",
    "                          batch_size=64, show_progress_bar=False)\n",
    "\n",
    "q_vecs = embed_q(question)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate - Recall@k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(index, k=5):\n",
    "\n",
    "    D, I = index.search(q_vecs, k) #I : (n_q, k) doc indices\n",
    "    hit = 0\n",
    "    for candidate, answer in zip(I, gold):\n",
    "        if any(answer.lower() in corpus[i].lower() for i in candidate):\n",
    "            hit += 1\n",
    "        return hit*100/len(gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in [1, 3, 5]:\n",
    "    print(f\"HNSW Recall@{k}: {recall(index_hnsw, k):.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in [1, 3, 5]:\n",
    "    print(f\"Exact Recall@{k}: {recall(index_flat, k):.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plug into RAG Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "model_name = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "llm = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\", torch_dtype=torch.float16)\n",
    "\n",
    "generator = pipeline(\"text-generation\", model=llm, tokenizer=tokenizer, temperature = 0.1, max_new_tokens=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_dense(q, k=3):\n",
    "\n",
    "    qv = encoder.encode([q], normalize_embeddings=True)\n",
    "    D, I = index_hnsw.search(qv, k)\n",
    "    context = \"\\n\".join(corpus[i] for i in I[0])\n",
    "    prompt = (\"You are a question-answering system. Use the context. \\n\\n\"\n",
    "        \"Context: {context}\\n\\n\"\n",
    "        \"Question: {q}\\n\\n\"\n",
    "        \"Answer briefly:\"\n",
    "    )\n",
    "\n",
    "    return generator(prompt)[0][\"generated_text\"].split(\"Answer briefly:\")[-1].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [answer_dense(q, k=3) for q in tqdm.tqdm(question[:100])]\n",
    "\n",
    "predictions_formatted = []\n",
    "references_formatted = []\n",
    "\n",
    "for i, (pred, ref) in enumerate(zip(predictions, gold[:100])):\n",
    "    predictions_formatted.append({\"id\": str(i), \"prediction_text\": pred})\n",
    "    references_formatted.append({\"id\": str(i), \"answers\": {\"text\": [ref], \"answer_start\": [0]}})\n",
    "squad = evaluate.load(\"squad\")\n",
    "results = squad.compute(predictions=predictions_formatted, references=references_formatted)\n",
    "print(json.dumps(results, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tunable Hyper-parameters\n",
    "\n",
    "- Model Size: `bge-large-en` (1024 d) maybe improve recall at cost of more RAM\n",
    "- Untied encoders: Train a doc-encoder specialized for long passages, query-encoder for short questions (e.g. DPR)\n",
    "- Pooling: Mean Pool\n",
    "- ANN Knobs: raising `efSearch`(HNSW) from 64 -> 128 bumps recall but increase latency \n",
    "- Float16 vs float32: Saves 50% RAM, negligible recall drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
